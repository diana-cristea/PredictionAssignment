{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a986b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
    "#model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "texts = pd.read_csv(\"texts.csv\")\n",
    "texts.index= texts[\"id\"]\n",
    "\n",
    "for index, row in texts.iterrows():\n",
    "    texts.at[index, \"text\"]=row[\"text\"].lower()\n",
    "    \n",
    "del texts[\"id\"]\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "texts.head()\n",
    "\n",
    "train = train_df.copy(deep=True)\n",
    "train = train.astype({'Text A':'string','Text B':'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe60c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text A</th>\n",
       "      <th>Text B</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a long, long time ago there lived in a little ...</td>\n",
       "      <td>her husband gasped at the audacity of the idea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a long, long time ago there lived in a little ...</td>\n",
       "      <td>she ate her supper with a hearty appetite, sai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a long, long time ago there lived in a little ...</td>\n",
       "      <td>now it came to pass on the third day, that est...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a long, long time ago there lived in a little ...</td>\n",
       "      <td>the peasant promised to buy his daughters what...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a long, long time ago there lived in a little ...</td>\n",
       "      <td>diplomacy is the practice of conducting negoti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Text A  \\\n",
       "0  a long, long time ago there lived in a little ...   \n",
       "1  a long, long time ago there lived in a little ...   \n",
       "2  a long, long time ago there lived in a little ...   \n",
       "3  a long, long time ago there lived in a little ...   \n",
       "4  a long, long time ago there lived in a little ...   \n",
       "\n",
       "                                              Text B  Result  \n",
       "0  her husband gasped at the audacity of the idea...       0  \n",
       "1  she ate her supper with a hearty appetite, sai...       1  \n",
       "2  now it came to pass on the third day, that est...       1  \n",
       "3  the peasant promised to buy his daughters what...       1  \n",
       "4  diplomacy is the practice of conducting negoti...       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in train_df.iterrows():\n",
    "    train.at[index, \"Text A\"]= texts.at[train_df.at[index, \"Text A\"], 'text']\n",
    "    train.at[index, \"Text B\"]= texts.at[train_df.at[index, \"Text B\"], 'text']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656a2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6d30e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38939, 500)\n",
      "(38939, 500)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Count vectorization of text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus1 = train['Text A'].values\n",
    "corpus2 = train['Text B'].values \n",
    "corpus = texts[\"text\"].values\n",
    "# Creating the vectorizer\n",
    "vectorizer=feature_extraction.text.TfidfVectorizer(max_features=500, ngram_range=(1,8))\n",
    "#vectorizer = CountVectorizer(max_features=500)\n",
    "vectorizer.fit(corpus) \n",
    "# Converting the text to numeric data\n",
    "X1 = vectorizer.transform(corpus1)\n",
    "X2 = vectorizer.transform(corpus2) \n",
    "#print(vectorizer.get_feature_names())\n",
    " \n",
    "# Preparing Data frame For machine learning\n",
    "# Priority column acts as a target variable and other columns as predictors\n",
    "CountVectorizedData1=pd.DataFrame(X1.toarray(), columns=vectorizer.get_feature_names())\n",
    "#CountVectorizedData1.insert(0, \"textinit\",train['Text A'].values)\n",
    "CountVectorizedData1 = CountVectorizedData1.add_suffix('_1')\n",
    "print(CountVectorizedData1.shape)\n",
    "CountVectorizedData2=pd.DataFrame(X2.toarray(), columns=vectorizer.get_feature_names())\n",
    "#CountVectorizedData2.insert(0, \"textinit\",train['Text B'].values)\n",
    "CountVectorizedData2 = CountVectorizedData2.add_suffix('_2')\n",
    "print(CountVectorizedData2.shape)\n",
    "X_train=pd.concat([CountVectorizedData1,CountVectorizedData2], axis=1)\n",
    "y_train=train[\"Result\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4cec3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4194, 500)\n",
      "(4194, 500)\n"
     ]
    }
   ],
   "source": [
    "# Count vectorization of text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "validation_df = pd.read_csv(\"validation.csv\")\n",
    "validation = validation_df.copy(deep=True)\n",
    "validation = validation.astype({'Text A':'string','Text B':'string'})\n",
    "\n",
    "for index, row in validation_df.iterrows():\n",
    "    validation.at[index, \"Text A\"]= texts.at[validation_df.at[index, \"Text A\"], 'text']\n",
    "    validation.at[index, \"Text B\"]= texts.at[validation_df.at[index, \"Text B\"], 'text']\n",
    "\n",
    "corpus1 = validation['Text A'].values\n",
    "corpus2 = validation['Text B'].values \n",
    "# Creating the vectorizer\n",
    "#vectorizer = CountVectorizer(max_features=500)\n",
    "#vectorizer=feature_extraction.text.TfidfVectorizer(max_features=500, ngram_range=(1,6))\n",
    "# Converting the text to numeric data\n",
    "X1 = vectorizer.transform(corpus1)\n",
    "X2 = vectorizer.transform(corpus2) \n",
    "#print(vectorizer.get_feature_names())\n",
    " \n",
    "# Preparing Data frame For machine learning\n",
    "# Priority column acts as a target variable and other columns as predictors\n",
    "CountVectorizedData1=pd.DataFrame(X1.toarray(), columns=vectorizer.get_feature_names())\n",
    "#CountVectorizedData1.insert(0, \"textinit\",validation['Text A'].values)\n",
    "CountVectorizedData1 = CountVectorizedData1.add_suffix('_1')\n",
    "print(CountVectorizedData1.shape)\n",
    "CountVectorizedData2=pd.DataFrame(X2.toarray(), columns=vectorizer.get_feature_names())\n",
    "#CountVectorizedData2.insert(0, \"textinit\",validation['Text B'].values)\n",
    "CountVectorizedData2 = CountVectorizedData2.add_suffix('_2')\n",
    "print(CountVectorizedData2.shape)\n",
    "X_validation=pd.concat([CountVectorizedData1,CountVectorizedData2], axis=1)\n",
    "#X_validation = X_validation.drop([text])\n",
    "y_validation=validation[\"Result\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87bb4c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1947/1947 [==============================] - 2s 804us/step - loss: 0.6224 - accuracy: 0.6514\n",
      "Epoch 2/10\n",
      "1947/1947 [==============================] - 2s 839us/step - loss: 0.5945 - accuracy: 0.6802\n",
      "Epoch 3/10\n",
      "1947/1947 [==============================] - 2s 855us/step - loss: 0.5662 - accuracy: 0.7043\n",
      "Epoch 4/10\n",
      "1947/1947 [==============================] - 2s 812us/step - loss: 0.5228 - accuracy: 0.7392\n",
      "Epoch 5/10\n",
      "1947/1947 [==============================] - 2s 792us/step - loss: 0.4742 - accuracy: 0.7718\n",
      "Epoch 6/10\n",
      "1947/1947 [==============================] - 2s 795us/step - loss: 0.4231 - accuracy: 0.8007\n",
      "Epoch 7/10\n",
      "1947/1947 [==============================] - 2s 809us/step - loss: 0.3722 - accuracy: 0.8216\n",
      "Epoch 8/10\n",
      "1947/1947 [==============================] - 2s 782us/step - loss: 0.3084 - accuracy: 0.8389\n",
      "Epoch 9/10\n",
      "1947/1947 [==============================] - 2s 794us/step - loss: 0.1476 - accuracy: 0.8397\n",
      "Epoch 10/10\n",
      "1947/1947 [==============================] - 2s 784us/step - loss: -0.6375 - accuracy: 0.8189\n",
      "132/132 [==============================] - 0s 550us/step\n",
      "0.6132570338578922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import  plot_confusion_matrix, balanced_accuracy_score, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=50, activation='relu', input_dim=len(X_train.columns)))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=20)\n",
    "\n",
    "base_preds=model.predict(X_validation)\n",
    "base_preds = [0 if val < 0.5 else 1 for val in base_preds]\n",
    "m1=accuracy_score(y_validation, base_preds)\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d21dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
